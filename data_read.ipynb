{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and merge csv files (Weather)\n",
    "read_weather = True\n",
    "# process and save processed csv files (Weather)\n",
    "process_weather = True\n",
    "station_name = 'Brooks'\n",
    "\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# GENERATION\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# read and merge csv files (Generation)\n",
    "read_generation = True\n",
    "# read and merge csv files (Generation)\n",
    "save_process_generation = True\n",
    "asset_name = \"BSC1 Brooks Solar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(file_path: os.PathLike):\n",
    "    df = pd.read_csv(file_path, encoding='unicode_escape')  # Read CSV file with proper encoding\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]  # Remove any \"Unnamed\" columns that might be auto-generated\n",
    "    return df  # Return the cleaned DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv files and merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV file saved successfully!\n",
      "Merged data has 43843 rows.\n"
     ]
    }
   ],
   "source": [
    "# Read CSVs and drop any unnamed index column\n",
    "if read_weather:\n",
    "    # Create a new folder to save the merged CSV file\n",
    "    os.makedirs('./Data/Merged', exist_ok=True)\n",
    "    # Load cleaned CSVs (each file contains data for a specific time period)\n",
    "    file_path = f\"./Data/ACIS/{station_name}\"\n",
    "    all_weather_data = pd.concat([clean_df(f'{file_path}/{file}') for file in os.listdir(f'{file_path}')], ignore_index=True)\n",
    "    # Save the merged dataframe as a new CSV file without index values\n",
    "    all_weather_data.to_csv(f\"./Data/Merged/{station_name}_weather_data.csv\", index=False)  # `index=False` prevents writing index column to CSV\n",
    "    print('Merged CSV file saved successfully!')\n",
    "    print(f\"Merged data has {all_weather_data.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_weather_station_data(df: pd.DataFrame, save: bool = False, columns = ['Date', 'Air Temp. Inst. (Â°C)', 'Humidity Inst. (%)', 'Incoming Solar Rad. (W/m2)','Precip. (mm)', 'Wind Speed 10 m Syno. (km/h)', 'Wind Dir. 10 m Syno. (Â°)', 'Wind Speed 10 m Avg. (km/h)', 'Wind Dir. 10 m Avg. (Â°)',]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get data for a specific asset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(df.columns)\n",
    "        df['Date'] = pd.to_datetime(df['Date (Local Standard Time)'], errors='coerce')        \n",
    "        columns_to_drop = [column for column in df.columns if column not in columns]\n",
    "        df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "        print(df.isna().sum())\n",
    "        df.fillna(method='ffill', inplace=True)\n",
    "        if save:\n",
    "            df.to_csv(f'./Data/Merged/{station_name}_weather.csv', index=False)\n",
    "            print('Processed CSV file saved successfully!')\n",
    "        print(\"Miissing values filled\")\n",
    "        print(f\"Data for {station_name} has {df.shape[0]} rows.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"No data found for {station_name}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Station Name', 'Date (Local Standard Time)', 'Air Temp. Inst. (Â°C)',\n",
      "       'Air Temp. Inst. Source Flag', 'Air Temp. Inst. Comment',\n",
      "       'Humidity Inst. (%)', 'Humidity Inst. Source Flag',\n",
      "       'Humidity Inst. Comment', 'Incoming Solar Rad. (W/m2)',\n",
      "       'Incoming Solar Rad. Source Flag', 'Incoming Solar Rad. Comment',\n",
      "       'Precip. (mm)', 'Precip. Source Flag', 'Precip. Comment',\n",
      "       'Wind Speed 10 m Syno. (km/h)', 'Wind Speed 10 m Syno. Source Flag',\n",
      "       'Wind Speed 10 m Syno. Comment', 'Wind Dir. 10 m Syno. (Â°)',\n",
      "       'Wind Dir. 10 m Syno. Source Flag', 'Wind Dir. 10 m Syno. Comment',\n",
      "       'Wind Speed 10 m Avg. (km/h)', 'Wind Speed 10 m Avg. Source Flag',\n",
      "       'Wind Speed 10 m Avg. Comment', 'Wind Dir. 10 m Avg. (Â°)',\n",
      "       'Wind Dir. 10 m Avg. Source Flag', 'Wind Dir. 10 m Avg. Comment'],\n",
      "      dtype='object')\n",
      "Air Temp. Inst. (Â°C)              0\n",
      "Humidity Inst. (%)                 0\n",
      "Incoming Solar Rad. (W/m2)         0\n",
      "Precip. (mm)                       0\n",
      "Wind Speed 10 m Syno. (km/h)       0\n",
      "Wind Dir. 10 m Syno. (Â°)       1398\n",
      "Wind Speed 10 m Avg. (km/h)        0\n",
      "Wind Dir. 10 m Avg. (Â°)        1398\n",
      "Date                               0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_18572\\1026872937.py:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed CSV file saved successfully!\n",
      "Miissing values filled\n",
      "Data for Brooks has 43843 rows.\n",
      "       Air Temp. Inst. (Â°C)  Humidity Inst. (%)  Incoming Solar Rad. (W/m2)  \\\n",
      "0                       -1.3                83.0                         0.0   \n",
      "1                       -0.6                79.0                         0.0   \n",
      "2                       -1.9                82.0                         0.0   \n",
      "3                       -2.3                86.0                         0.0   \n",
      "4                       -1.8                83.0                         0.0   \n",
      "...                      ...                 ...                         ...   \n",
      "43838                  -11.4                89.0                         0.0   \n",
      "43839                  -10.5                88.0                         0.0   \n",
      "43840                  -10.6                87.0                         0.0   \n",
      "43841                  -10.8                86.0                         0.0   \n",
      "43842                  -11.1                87.0                         0.0   \n",
      "\n",
      "       Precip. (mm)  Wind Speed 10 m Syno. (km/h)  Wind Dir. 10 m Syno. (Â°)  \\\n",
      "0               0.0                           9.7                      287.0   \n",
      "1               0.0                          11.9                      314.0   \n",
      "2               0.0                           9.6                      335.0   \n",
      "3               0.0                           9.3                      345.0   \n",
      "4               0.0                           9.3                      347.0   \n",
      "...             ...                           ...                        ...   \n",
      "43838           0.0                           1.1                       41.0   \n",
      "43839           0.0                           4.7                       51.0   \n",
      "43840           0.3                           4.8                       50.0   \n",
      "43841           0.2                           6.1                       46.0   \n",
      "43842           0.3                           3.2                       33.0   \n",
      "\n",
      "       Wind Speed 10 m Avg. (km/h)  Wind Dir. 10 m Avg. (Â°)  \\\n",
      "0                             12.9                     279.0   \n",
      "1                              9.9                     303.0   \n",
      "2                             11.0                     322.0   \n",
      "3                             10.9                     341.0   \n",
      "4                              8.7                     338.0   \n",
      "...                            ...                       ...   \n",
      "43838                          3.2                      39.0   \n",
      "43839                          2.8                      53.0   \n",
      "43840                          4.0                      55.0   \n",
      "43841                          6.1                      48.0   \n",
      "43842                          3.8                      39.0   \n",
      "\n",
      "                     Date  \n",
      "0     2020-01-01 00:00:00  \n",
      "1     2020-01-01 01:00:00  \n",
      "2     2020-01-01 02:00:00  \n",
      "3     2020-01-01 03:00:00  \n",
      "4     2020-01-01 04:00:00  \n",
      "...                   ...  \n",
      "43838 2024-12-31 19:00:00  \n",
      "43839 2024-12-31 20:00:00  \n",
      "43840 2024-12-31 21:00:00  \n",
      "43841 2024-12-31 22:00:00  \n",
      "43842 2024-12-31 23:00:00  \n",
      "\n",
      "[43843 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the merged CSV file\n",
    "weather_data = clean_df(f\"./Data/Merged/{station_name}_weather_data.csv\")\n",
    "if process_weather:\n",
    "    station_data = process_weather_station_data(weather_data, save=True)\n",
    "    # Convert Data\n",
    "    print(station_data)\n",
    "    # Create a new folder to save the merged CSV file\n",
    "    os.makedirs('./Data/Merged', exist_ok=True)\n",
    "    # Fill missing values with the average of previous and next values\n",
    "    # print(station_data.isna().sum())\n",
    "    # print(f\"Processed data has {station_data.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv files and merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV file saved successfully!\n",
      "Merged data has 7252077 rows.\n"
     ]
    }
   ],
   "source": [
    "if read_generation:\n",
    "    # Load data using a for loop and a list comprehension\n",
    "    generation_data = pd.concat([clean_df(f'./Data/CSD/{file}') for file in os.listdir('./Data/CSD')], ignore_index=True)\n",
    "    # Create a new folder to save the merged CSV file\n",
    "    os.makedirs('./Data/Merged', exist_ok=True)\n",
    "    # Save the merged dataframe as a new CSV file without index values\n",
    "    generation_data.to_csv('./Data/Merged/Generation.csv', index=False)  # `index=False` prevents writing index column to CSV\n",
    "    print('Merged CSV file saved successfully!')\n",
    "    print(f\"Merged data has {generation_data.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find assets with most data in the generation data\n",
    "def get_assets_with_most_data(df: pd.DataFrame, fuel_type: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Get the assets with the most data points in the generation data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = df[df['Fuel Type'] == fuel_type.upper()]\n",
    "        asset_list = df['Asset Name'].value_counts()\n",
    "        most_valuable_asset = asset_list.where(asset_list == asset_list[0]).dropna()\n",
    "        print(f\"Total number of assets: {len(asset_list)}\")\n",
    "        print(f\"{len(most_valuable_asset)} assets have the most data. They have {most_valuable_asset[0]} data points.\")\n",
    "        return most_valuable_asset\n",
    "    except Exception as e:\n",
    "        print(f\"No data found for {fuel_type} assets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for a specific asset.\n",
    "def get_asset_data(df: pd.DataFrame, asset_name: str, save: bool = False, columns = ['Volume', 'Maximum Capability', 'System Capability']) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get data for a specific asset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        asset_data = df[df['Asset Name'] == asset_name]\n",
    "        columns_to_drop = [column for column in asset_data.columns if column not in columns]\n",
    "        asset_data['Date'] = pd.to_datetime(asset_data['Date (MST)'], errors='coerce')\n",
    "        asset_data.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "        print(asset_data.isna().sum())\n",
    "        asset_data.fillna(method='ffill', inplace=True)\n",
    "        if save:\n",
    "            asset_data.to_csv(f'./Data/Merged/{asset_name}_generation.csv', index=False)\n",
    "            print('Processed CSV file saved successfully!')\n",
    "        print(\"Miissing values filled\")\n",
    "        print(f\"Data for {asset_name} has {asset_data.shape[0]} rows.\")\n",
    "        return asset_data\n",
    "    except Exception as e:\n",
    "        print(f\"No data found for {asset_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read merged data\n",
    "generation_data = clean_df('./Data/Merged/Generation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_assets_with_most_data(generation_data,'wind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_18572\\1683497974.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  asset_data['Date'] = pd.to_datetime(asset_data['Date (MST)'], errors='coerce')\n",
      "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_18572\\1683497974.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  asset_data.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
      "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_18572\\1683497974.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  asset_data.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_18572\\1683497974.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  asset_data.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume                0\n",
      "Maximum Capability    0\n",
      "System Capability     0\n",
      "Date                  0\n",
      "dtype: int64\n",
      "Processed CSV file saved successfully!\n",
      "Miissing values filled\n",
      "Data for BSC1 Brooks Solar has 43848 rows.\n"
     ]
    }
   ],
   "source": [
    "asset_gen_data = get_asset_data(generation_data, asset_name, save_process_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged file has 43843 rows.\n",
      "Volume                          0\n",
      "Maximum Capability              0\n",
      "System Capability               0\n",
      "Date                            0\n",
      "Air Temp. Inst. (Â°C)           0\n",
      "Humidity Inst. (%)              0\n",
      "Incoming Solar Rad. (W/m2)      0\n",
      "Precip. (mm)                    0\n",
      "Wind Speed 10 m Syno. (km/h)    0\n",
      "Wind Dir. 10 m Syno. (Â°)       0\n",
      "Wind Speed 10 m Avg. (km/h)     0\n",
      "Wind Dir. 10 m Avg. (Â°)        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(asset_gen_data, weather_data, on='Date', how='inner')\n",
    "merged_rows = merged_df.shape[0]\n",
    "print(f\"The merged file has {merged_rows} rows.\")\n",
    "print(merged_df.isna().sum())\n",
    "merged_df.to_csv(f\"./Data/Merged/{asset_name}_Processed_and_Data.csv\", index=False)  # `index=False` prevents writing index column to CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enel678",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
